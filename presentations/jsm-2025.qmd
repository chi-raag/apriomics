---
title: Automated Prior Elicitation for Bayesian Metabolomics Analysis
subtitle: JSM 2025 | Flexible Prior Elicitation for Bayesian Analysis 
author: Chiraag Gohel
date: August 6, 2025
institute: The Rahnavard Lab, The George Washington University
logo: images/gw_primary_2c_0.png
bibliography: references.bib
csl: https://www.zotero.org/styles/american-statistical-association
suppress-bibliography: true
fig-dpi: 150
format: 
    revealjs: 
        theme: gw.scss
        html-math-method: mathjax
        slide-number: true
        title-slide-attributes:
            data-background-image: https://dtais.engineering.gwu.edu/sites/g/files/zaxdzs4921/files/header_block/DTAIS%20logo_1c.png, https://rahnavard.org/media/logo_hu6032439a0cdf518af9f282061b335860_10275_0x70_resize_lanczos_3.png
            data-background-size: 210px, 75px
            data-background-position: 87% 99%, 93% 99%
        width: 1600
        height: 1000
        pdf-separate-fragments: true
mermaid-format: svg
---

# Introduction


## What is metabolomics?


![From Human Metabolome Technologies](https://humanmetabolome.com/ap/wp-content/uploads/2020/11/metabolomics_01.png){width="80%"}


::: {.notes}
- Comprehensively profile small-molecule metabolites in cells, tissues, or biofluids to capture the biochemical “phenotype” in real time.
- Link upstream omics to downstream phenotype: bridge the gap between genomic/proteomic signals and observable physiology or disease states.
- Detect pathway-level perturbations (e.g., energy, lipid, or amino-acid metabolism) that underlie exposures, interventions, or pathology.
- Discover and validate biomarkers for diagnosis, prognosis, or treatment response
:::

## Traditional testing lacks power

![Henglin, M. et al. (2022), “Quantitative Comparison of Statistical Methods for Analyzing Human Metabolomics Data,” Metabolites, 12, 519. 
](images/univariate_simulation.png)

## Effect size drives biological insight


:::: {.columns}

::: {.column width="70%"}


![Liang, H., and Song, K. (2023), [“Comprehensive metabolomics and transcriptomics analysis reveals protein and amino acid metabolic characteristics in liver tissue under chronic hypoxia,”](https://doi.org/10.1371/journal.pone.0291798) PLOS ONE, Public Library of Science, 18, e0291798.](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0291798.g001&type=large)

:::

::: {.column width="30%" .fragment}

![](https://upload.wikimedia.org/wikipedia/en/e/ec/Human_Metabolome_Database_logo.png){width="60%"}

![](https://pubchem.ncbi.nlm.nih.gov/pcfe/logo/PubChem_logo.png){width="60%"}

:::{.fragment}

**Can we use LLMs as "experts" to inform priors in Bayesian metabolomics models?**

:::

:::

::::


## Prior work

:::{.fragment}
![Zhang, E. et al. (2025), [“LLM-Lasso: A Robust Framework for Domain-Informed Feature Selection and Regularization,”](https://doi.org/10.48550/arXiv.2502.10648) arXiv.](https://arxiv.org/html/2502.10648v2/x1.png){width="80%" fig-align="center"}
:::

:::{.fragment}
![Capstick, A. et al. (2025), [“AutoElicit: Using Large Language Models for Expert Prior Elicitation in Predictive Modelling,”](https://doi.org/10.48550/arXiv.2411.17284.) arXiv.](https://arxiv.org/html/2411.17284v5/x1.png){width="80%"}
:::

## Prior elicitation framework overview

![](./images/overview.png){width="100%"}

::: {.incremental}

- Do LLMs require extra knowledge from databases or literature?
- How do different prompt formulations affect effect size estimation?
- Can this process be automated for high-throughput metabolomics studies?

:::


# Methods

## LLM prior elicitation process

::: {.fragment}
**Approach 1: Categorical Mapping**
$$\text{LLM}(\text{metabolite}, \text{condition}) \rightarrow \{d_j, m_j, c_j, r_j\}$$

where $d_j \in \{\text{increase, decrease, unchanged}\}$ is predicted direction, $m_j \in \{\text{small, moderate, large}\}$ is predicted magnitude, $c_j \in \left(0, 1\right)$ is confidence level, and $r_j$ is a string representing the rationale.

Then map to numerical priors: $\mu_j^{\text{LLM}} = f_{\mu}(m_j, d_j)$, $\sigma_j^{\text{LLM}} = f_{\sigma}(c_j)$
:::

::: {.fragment}
**Approach 2: Direct Numerical**
$$\text{LLM}(\text{metabolite}, \text{condition}) \rightarrow \{\mu_j, \sigma_j, r_j\}$$

where LLM directly outputs numerical estimates: $\mu_j \in \mathbb{R}$ is predicted log fold change, $\sigma_j > 0$ is prediction uncertainty, and $r_j$ is reasoning.

No mapping required: use LLM outputs directly as $\mu_j^{\text{LLM}} = \mu_j$, $\sigma_j^{\text{LLM}} = \sigma_j$
:::

::: {.fragment}
**Both approaches**: Use as informative priors in Bayesian model
$\beta_j \sim \mathcal{N}(\mu_j^{\text{LLM}}, \sigma_j^{\text{LLM}})$
:::

## Priors

**LLM Priors**: $\beta_j \sim \mathcal{N}(\mu_j^{\text{LLM}}, \sigma_j^{\text{LLM}})$

where $\mu_j^{\text{LLM}}$ and $\sigma_j^{\text{LLM}}$ are derived from LLM predictions:

\begin{align}
\mu_j^{\text{LLM}} &= m_j \cdot \text{sign}(d_j) \\
\sigma_j^{\text{LLM}} &= f(c_j)
\end{align}

:::: {.columns}

::: {.column width="45%"}
**Conservative Mapping**

$m_j \in \{0.08, 0.15, 0.25\}$ for $\{\text{small, moderate, large}\}$

$f(c_j) \in \{0.5, 0.7, 0.9\}$ for $\{\text{high, med, low}\}$ confidence
:::

::: {.column width="45%"}
**Moderate Mapping**
$m_j \in \{0.12, 0.22, 0.35\}$ for $\{\text{small, moderate, large}\}$

$f(c_j) \in \{0.3, 0.5, 0.7\}$ for $\{\text{high, med, low}\}$ confidence
:::

::::

**Oracle Prior (Upper Bound)**: $\beta_j \sim \mathcal{N}(\beta_j^{\text{true}}, 0.25)$

**Weakly Informative Prior**: $\beta_j \sim \mathcal{N}(0, 2)$

## LLM-Informed Hierarchical Prior {visibility="hidden"}

Group metabolites by LLM predictions and use intelligent pooling:

\begin{align*}
\text{Group means}_g &\sim \mathcal{N}\bigl(\mu_g^{\mathrm{LLM}}, 3.0\bigr) \\
\beta_j &\sim \mathcal{N}\bigl(\text{Group means}_{g[j]}, 2.0\bigr)
\end{align*}

where group $g$ is mapped to $\mu_g^{\mathrm{LLM}}$ as follows:

\begin{align*}
\mu_g^{\mathrm{LLM}} =
\begin{cases}
-0.1, & \text{if }g = \text{decrease},\\
0.0,  & \text{if }g = \text{unchanged},\\
+0.1, & \text{if }g = \text{increase}.
\end{cases}
\end{align*}


## Modeling

All Bayesian models use the same log-link GLM structure with different prior specifications:

\begin{align}
y_{ij} &\sim \mathcal{N}(\mu_{ij}, \sigma_j^2) \\
\log(\mu_{ij}) &= \alpha_j + \beta_j \cdot x_i \\
\alpha_j &\sim \mathcal{N}(\log(\bar{y}_j + \epsilon), 1.0) \\
\sigma_j &\sim \text{HalfNormal}(0.5)
\end{align}

where $y_{ij}$ is abundance for sample $i$ and metabolite $j$, $x_i \in \{0,1\}$ is group indicator, $\beta_j$ represents the natural log fold change (lnFC) for metabolite $j$, and $\epsilon$ is a small constant to avoid log(0).

## Simulation Study

### Empirical Monte-Carlo Subsampling

```{mermaid} 
%%| fig-height: 5
%%| fig-width: 14
---
config:
    theme: 'base'
    themeVariables:
        fontFamily: Mona Sans
        primaryColor: '#F8E08E'
        secondaryColor: '#0190DB'
---
graph TD;
    A[Full Dataset] --> B[Subsample Data]
    A --> C[Calculate true lnFC]
    B --> D[Fit Models]
    E[Weakly Informative Priors] --> D
    F[LLM Priors] --> D
    G[HMDB + LLM Priors] --> D
    D --> H[Compare estimators]
    C --> H

classDef prior fill:white;
class E,F,G prior;
```

**Ground Truth**: Empirical natural log fold change (lnFC) from full MTBLS1 dataset^[Salek, R. M. et al. (2007), [“A metabolomic comparison of urinary changes in type 2 diabetes in mouse, rat, and human,”](https://doi.org/10.1152/physiolgenomics.00194.2006.) Physiological Genomics, American Physiological Society.]: $\beta_j^{\text{true}} = \log\left(\frac{\bar{y}_j^{\text{case}}}{\bar{y}_j^{\text{control}}}\right)$ (n=132)

# Results

## Examples of LLM Output

:::: {layout="[30, -30, 10, -20]"}

**Acetoacetate**

![](https://www.sigmaaldrich.com/deepweb/assets/sigmaaldrich/product/structures/344/649/4f016901-2115-4196-8191-7aeee6a5f0f3/640/4f016901-2115-4196-8191-7aeee6a5f0f3.png)

::::


- Prediction: increase
- Magnitude: moderate
- Confidence: 0.8
- Reasoning: "Acetoacetate is a ketone body produced during fatty acid oxidation. In type 2 diabetes, even with good dietary control, insulin resistance promotes increased lipolysis which mildly enhances ketogenesis. 


## LLM-informed priors improve recovery at low sample sizes

::: {.r-stack}

```{r}
library(tidyverse)
library(ggnewscale)
library(ggplot2)
library(gghighlight)
library(viridis)

full_data <- read_csv("../output/benchmark_raw_estimates.csv")

data <- full_data |>
    mutate(method = factor(method, levels = c(
        "uninformative_bayesian",
        "4o_no_context_conservative", "4o_with_context_conservative",
        "4o_no_context_quantitative", "4o_with_context_quantitative",
        "o3-mini_no_context_conservative", "o3-mini_with_context_conservative",
        "o3-mini_no_context_quantitative", "o3-mini_with_context_quantitative",
        "o3_no_context_conservative", "o3_no_context_quantitative",
        "oracle_bayesian"
    ))) |>
    mutate(
        llm = case_when(
            str_detect(method, "4o") ~ "GPT-4o",
            str_detect(method, "o3-mini") ~ "O3 Mini",
            str_detect(method, "uninformative") ~ "Uninformative",
            str_detect(method, "oracle") ~ "Oracle",
            TRUE ~ "O3"
        )
    ) |>
    mutate(
        type = case_when(
            str_detect(method, "quantitative") ~ "N",
            str_detect(method, "conservative") ~ "C",
            TRUE ~ NA
        )
    ) |>
    mutate(llm = factor(llm, levels = c("Uninformative", "GPT-4o", "O3", "O3 Mini", "Oracle"))) |>
    mutate(
        context = case_when(
            str_detect(method, "no_context") ~ "No Context",
            str_detect(method, "with_context") ~ "Context",
            TRUE ~ NA
        ),
        short_ctx = case_when(
            context == "Context" ~ "+",
            context == "No Context" ~ "-"
        )
    ) |>
    group_by(replicate, sample_size, method, llm, short_ctx, context, type)

data_rmse <- data |> summarise(rmse = sqrt(mean((ground_truth - estimate)^2, na.rm = TRUE)), .groups = "drop")



sample_labeller <- labeller(
    sample_size = c(
        `5`  = "n = 5",
        `10` = "n = 10",
        `15` = "n = 15",
        `20` = "n = 20"
    )
)

label_data_rmse_context <- data_rmse %>%
    filter(!is.na(context)) %>%
    group_by(sample_size, method, context, short_ctx) %>%
    summarize(max_rmse = max(rmse, na.rm = TRUE), .groups = "drop") %>%
    group_by(sample_size) %>%
    mutate(y_pos = max(max_rmse) + .01) %>%
    ungroup()

label_data_rmse_type <- data_rmse %>%
    filter(!is.na(type)) %>%
    group_by(sample_size, method, type) %>%
    summarize(max_rmse = max(rmse, na.rm = TRUE), .groups = "drop") %>%
    group_by(sample_size) %>%
    mutate(y_pos = max(max_rmse) + .02) %>%
    ungroup()


data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "black", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```

::: {.fragment}

```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    gghighlight(llm == "Uninformative", 
    unhighlighted_params = list(fill = NULL, alpha = 0.3),
    keep_scales = TRUE,
    calculate_per_facet = TRUE
) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```

:::


::: {.fragment}

```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    gghighlight(context == "Context", 
    unhighlighted_params = list(fill = NULL, alpha = 0.3),
    keep_scales = TRUE,
    calculate_per_facet = TRUE
) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```
:::


::: {.fragment}
```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    gghighlight(context == "No Context", 
    unhighlighted_params = list(fill = NULL, alpha = 0.3),
    keep_scales = TRUE,
    calculate_per_facet = TRUE
) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```
:::

::: {.fragment}
```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    gghighlight(type == "N", 
    unhighlighted_params = list(fill = NULL, alpha = 0.3),
    keep_scales = TRUE,
    calculate_per_facet = TRUE
) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```
:::

::: {.fragment}
```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    gghighlight(type == "C", 
    unhighlighted_params = list(fill = NULL, alpha = 0.3),
    keep_scales = TRUE,
    calculate_per_facet = TRUE
) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```
:::

::: {.fragment}

```{r}
data_rmse |>
    ggplot(aes(x = method, y = rmse, fill = llm)) +
    geom_boxplot(outliers = FALSE) +
    scale_fill_viridis(discrete = TRUE) +
    geom_point(aes(x = method, y = rmse, fill = llm), color = "white", shape = 21, alpha = .4, show.legend = FALSE) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_context,
        aes(x = method, y = y_pos, label = short_ctx, color = context),
        size = 5,
        show.legend = FALSE
    ) +
    geom_text(
        inherit.aes = FALSE,
        data = label_data_rmse_type,
        aes(x = method, y = y_pos, label = type),
        size = 3,
        show.legend = FALSE
    ) +
    scale_color_manual(
        name = "Context",
        values = c(
            "Context" = "black",
            "No Context" = "black"
        ),
        breaks = c("Context", "No Context"),
        labels = c("With Context", "No Context")
    ) +
    facet_grid(~sample_size, scales = "free_x", labeller = sample_labeller) +
    theme_bw(base_size = 18, base_family = "Mona Sans") +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.line.x = element_blank(),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        panel.grid = element_blank()
    ) +
    labs(
        y     = "Root Mean Squared Error (RMSE)",
        fill  = "",
        color = "Context"
    )
```

:::

:::

## Bias-Variance Decomposition

::: {.r-stack}

```{r}
#| echo: false
#| warning: false

# Calculate bias-variance per replicate for confidence ellipses
bias_var_per_rep <- full_data %>%
    filter(method %in% c("4o_no_context_quantitative", "4o_no_context_conservative", "oracle_bayesian", "uninformative_bayesian")) %>%
    group_by(replicate, method, sample_size, metabolite) %>%
    summarise(
        mean_estimate = mean(estimate, na.rm = TRUE),
        ground_truth = first(ground_truth),
        .groups = "drop"
    ) %>%
    group_by(replicate, method, sample_size) %>%
    summarise(
        bias_squared = mean(mean_estimate - ground_truth, na.rm = TRUE)^2,
        variance = var(mean_estimate, na.rm = TRUE),
        .groups = "drop"
    ) %>%
    mutate(
        method_clean = case_when(
            method == "4o_no_context_quantitative" ~ "4o (N)",
            method == "4o_no_context_conservative" ~ "4o (C)",
            method == "oracle_bayesian" ~ "Oracle",
            method == "uninformative_bayesian" ~ "Uninformative"
        )
    )

# Create bias-variance plot with confidence regions
bias_var_per_rep %>%
    ggplot(aes(x = bias_squared, y = variance, color = method_clean)) +
    stat_ellipse(level = .68, size = 2, type = "t", alpha = .4) +  # 1 SE region
    scale_color_viridis(option = "turbo", discrete = TRUE) +
    geom_point(size = 1, alpha = 0.8) +
    facet_wrap(~sample_size, labeller = labeller(sample_size = function(x) paste("n =", x))) +
    theme_bw(base_family = "Mona Sans", base_size = 16) +
    theme(
        panel.grid = element_blank()
    ) +
    labs(
        x = "Bias²",
        y = "Variance",
        color = "Method"
    ) 
```

::: {.fragment}
```{r}
#| echo: false
#| warning: false
#| message: false
bias_var_per_rep %>%
    ggplot(aes(x = bias_squared, y = variance, color = method_clean)) +
    stat_ellipse(level = .68, type = "t", size = 2, alpha = .4) +  # 1 SE region
    gghighlight(method_clean == "Uninformative" | method_clean == "Oracle", unhighlighted_params = list(color = NULL, alpha = 0.3), keep_scales = TRUE, calculate_per_facet = TRUE) +
    scale_color_viridis(option = "turbo", discrete = TRUE) +
    geom_point(size = 1, alpha = 0.8) +
    facet_wrap(~sample_size, labeller = labeller(sample_size = function(x) paste("n =", x))) +
    theme_bw(base_family = "Mona Sans", base_size = 16) +
    theme(
        panel.grid = element_blank()
    ) +
    labs(
        x = "Bias²",
        y = "Variance",
        color = "Method"
    ) 
```
:::

::: {.fragment}
```{r}
#| echo: false
#| warning: false
#| message: false
bias_var_per_rep %>%
    ggplot(aes(x = bias_squared, y = variance, color = method_clean)) +
    stat_ellipse(level = .68, type = "t", size = 2, alpha = .4) +  # 1 SE region
    gghighlight(method_clean %in% c("4o (N)", "4o (C)", "Oracle"), unhighlighted_params = list(color = NULL, alpha = 0.3), keep_scales = TRUE, calculate_per_facet = TRUE) +
    scale_color_viridis(option = "turbo", discrete = TRUE) +
    geom_point(size = 1, alpha = 0.8) +
    facet_wrap(~sample_size, labeller = labeller(sample_size = function(x) paste("n =", x))) +
    theme_bw(base_family = "Mona Sans", base_size = 16) +
    theme(
        panel.grid = element_blank()
    ) +
    labs(
        x = "Bias²",
        y = "Variance",
        color = "Method"
    ) 
```
:::


:::

## Summary

- **LLM Prior Elicitation Works**
- **Mapping Strategy Matters**
- **Added Context May Not Matter**
- **Performance is Model Agnostic**
- **Larger Gains at Small Sample Sizes**

## {background-image="images/ack.png" background-size="contain"}